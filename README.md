# Unbaised-Mental-Health-Classifier
In many real-world applications of machine learning predictive models can inadvertently exhibit bias against certain groups of individuals defined by sensitive attributes like gender, race, or age. This happens because models often learn patterns from historical data, which may reflect societal biases.

Therefore I developed a machine learning model that not only achieves high accuracy in its predictions but also ensures fairness, meaning that its decisions are not influenced disproportionately by sensitive attributes. Specifically, we aim to reduce the Demographic Parity Gap, which measures the disparity in positive outcomes (e.g., approvals or classifications) between different demographic groups.

## Requirenment
-  Pandas
-  Pytorch
-  transformers
-  Sklearn
-  matplotlib

